{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `predict()`: save npy files for convnet feature\n",
    "* `get_mfcc()`: save npy file for mfcc (+d, dd) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import keras\n",
    "import models_transfer\n",
    "from argparse import Namespace\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "from keras import backend as K\n",
    "from utils_featext import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOBAL SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A base path for datasets\n",
    "PATH_DATASETS = '/home/kchow/datasets/'\n",
    "# Jamendo is here after trimming\n",
    "PATH_PROCESSED = '/home/kchow/datasets/datasets_processed/'\n",
    "PATH_URBANSOUND = '/home/kchow/datasets/UrbanSound8K/audio/'\n",
    "# A folder to store csv files\n",
    "FOLDER_CSV = '/home/kchow/TLMusic/data_csv/'\n",
    "# A folder to store extracted features\n",
    "FOLDER_FEATS = '/home/kchow/TLMusic/data_feats/'\n",
    "if not os.path.exists(FOLDER_CSV):\n",
    "    os.mkdir(FOLDER_CSV)\n",
    "if not os.path.exists(FOLDER_FEATS):\n",
    "    os.mkdir(FOLDER_FEATS)\n",
    "\n",
    "# Some constants for my convnet\n",
    "SR = 12000 # [Hz]\n",
    "len_src = 29. # [second]\n",
    "N_JOBS = 9\n",
    "ref_n_src = 12000 * 29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `PATH_DATASETS`:\n",
    "\n",
    "```shell\n",
    "keunwoo@weaver4[datasets]$ pwd\n",
    "/misc/kcgscratch1/ChoGroup/keunwoo/datasets\n",
    "keunwoo@weaver4[datasets]$ ls -l\n",
    "drwx------. 16 keunwoo keunwoo       4096 Dec 29 16:42 ballroom_extended_2016\n",
    "drwx------.  3 keunwoo keunwoo       4096 Dec 29 16:19 emoMusic45s\n",
    "drwx------.  3 keunwoo keunwoo         27 Dec 29 16:19 gtzan_genre\n",
    "drwx------.  3 keunwoo keunwoo         33 Dec 29 16:20 gtzan_music_speech\n",
    "drwx------.  6 keunwoo keunwoo       4096 Dec 29 18:21 jamendo_voice_activity\n",
    "drwx------.  4 keunwoo keunwoo       4096 Nov 29 02:46 UrbanSound8K\n",
    "```\n",
    "\n",
    "In `PATH_PROCESSED`:\n",
    "\n",
    "```shell\n",
    "keunwoo@weaver4[datasets_processed]$ pwd\n",
    "/misc/kcgscratch1/ChoGroup/keunwoo/datasets_processed\n",
    "keunwoo@weaver4[datasets_processed]$ ls -l\n",
    "drwx------. 5 keunwoo keunwoo 57 Dec 29 19:20 jamendo_trimmed\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_filepaths(df, dataroot=None):\n",
    "    \"\"\"Generate file path (column name 'filepath') from given dataframe \"\"\"\n",
    "    if dataroot is None:\n",
    "        dataroot = PATH_DATASETS\n",
    "    for filepath in df['filepath']:\n",
    "        yield os.path.join(dataroot, filepath)\n",
    "\n",
    "def gen_audiofiles(df, batch_size=256, dataroot=None):\n",
    "    '''gen single audio file src in a batch_size=1 form for keras model.predict_generator\n",
    "    df: dataframe \n",
    "    total_size: integer.\n",
    "    batch_size: integer.\n",
    "    dataroot: root path for data'''\n",
    "\n",
    "    ''''''\n",
    "    pool = Pool(N_JOBS)\n",
    "    def _multi_loading(pool, paths):\n",
    "        srcs = pool.map(_load_audio, paths)\n",
    "        srcs = np.array(srcs)\n",
    "        try:\n",
    "            srcs = srcs[:, np.newaxis, :]\n",
    "        except:\n",
    "            pdb.set_trace()\n",
    "\n",
    "        return srcs\n",
    "    \n",
    "    total_size = len(df)\n",
    "    n_leftover = int(total_size % batch_size)\n",
    "    leftover = n_leftover != 0\n",
    "    n_batch = int(total_size / batch_size)\n",
    "    gen_f = gen_filepaths(df, dataroot=dataroot)\n",
    "    print('n_batch: {}, n_leftover: {}, all: {}'.format(n_batch, n_leftover, total_size))\n",
    "    \n",
    "    for batch_idx in xrange(n_batch):\n",
    "        paths = []\n",
    "        for inbatch_idx in range(batch_size):\n",
    "            paths.append(gen_f.next())\n",
    "        print('..yielding {}/{} batch..'.format(batch_idx, n_batch))                    \n",
    "        yield _multi_loading(pool, paths)\n",
    "        \n",
    "    if leftover:\n",
    "        paths = []\n",
    "        for inbatch_idx in range(n_leftover):\n",
    "            paths.append(gen_f.next())\n",
    "        print('..yielding final batch w {} data sample..'.format(len(paths)))\n",
    "        yield _multi_loading(pool, paths)\n",
    "\n",
    "def _load_audio(path):\n",
    "    \"\"\"Load audio file at path with sampling rate=SR, duration=len_src, and return it\"\"\"\n",
    "    src, sr = librosa.load(path, sr=SR, duration=len_src * SR / float(SR))\n",
    "    src = src[:ref_n_src]\n",
    "    result = np.zeros(ref_n_src)\n",
    "    result[:len(src)] = src[:ref_n_src]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for convnet feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(filename, batch_size, model, dataroot=None, npy_suffix=''):\n",
    "    \"\"\"Extract convnet feature using given model\"\"\"\n",
    "    if dataroot is None:\n",
    "        dataroot = PATH_DATASETS\n",
    "    start = time.time()\n",
    "    csv_filename = '{}.csv'.format(filename)\n",
    "    npy_filename = '{}{}.npy'.format(filename, npy_suffix)\n",
    "    df = pd.read_csv(os.path.join(FOLDER_CSV, csv_filename))\n",
    "    print('{}: Dataframe with size:{}').format(filename, len(df))\n",
    "    example_path = os.path.join(dataroot, df['filepath'][0])\n",
    "    print('An example path - does it exists? {}'.format(os.path.exists(example_path)))\n",
    "    print(df.columns)\n",
    "    gen_audio = gen_audiofiles(df, batch_size, dataroot)\n",
    "    feats = model.predict_generator(generator=gen_audio, \n",
    "                                    val_samples=len(df), \n",
    "                                    max_q_size=1)\n",
    "    np.save(os.path.join(FOLDER_FEATS, npy_filename), feats)\n",
    "    print('DONE! in {:6.4f} sec'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions for mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mfcc\n",
    "def get_mfcc(filename, dataroot=None):    \n",
    "    start = time.time()\n",
    "    csv_filename = '{}.csv'.format(filename)\n",
    "    npy_filename = '{}_mfcc.npy'.format(filename)\n",
    "    df = pd.read_csv(os.path.join(FOLDER_CSV, csv_filename))\n",
    "    print('{}: Dataframe with size:{}').format(filename, len(df))\n",
    "    #print(os.path.exists(os.path.join(dataroot, df['filepath'][0])))   \n",
    "    print(df.columns)\n",
    "    gen_f = gen_filepaths(df, dataroot=dataroot)\n",
    "\n",
    "    pool = Pool(N_JOBS)\n",
    "    paths = list(gen_f)\n",
    "    feats = pool.map(_path_to_mfccs, paths)\n",
    "    feats = np.array(feats)\n",
    "    np.save(os.path.join(FOLDER_FEATS, npy_filename), feats)\n",
    "    print('MFCC is done! in {:6.4f} sec'.format(time.time() - start))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "def _path_to_mfccs(path):\n",
    "    src_zeros = np.zeros(1024) # min length to have 3-frame mfcc's\n",
    "    src, sr = librosa.load(path, sr=SR, duration=29.) # max len: 29s, can be shorter.\n",
    "    if len(src) < 1024:\n",
    "        src_zeros[:len(src)] = src\n",
    "        src = src_zeros\n",
    "    \n",
    "    mfcc = librosa.feature.mfcc(src, SR, n_mfcc=20)\n",
    "    dmfcc = mfcc[:, 1:] - mfcc[:, :-1]\n",
    "    ddmfcc = dmfcc[:, 1:] - dmfcc[:, :-1]\n",
    "    return np.concatenate((np.mean(mfcc, axis=1), np.std(mfcc, axis=1),\n",
    "                           np.mean(dmfcc, axis=1), np.std(dmfcc, axis=1),\n",
    "                           np.mean(ddmfcc, axis=1), np.std(ddmfcc, axis=1))\n",
    "                          , axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract my convnet features\n",
    "## Models for layer 1-5 (or, 0-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "tasks.append(['ballroom_extended', 'gtzan_speechmusic'])\n",
    "#tasks.append(['emoMusic', 'jamendo_vd', 'urbansound', 'gtzan_genre', ])\n",
    "tasks.append(['urbansound', 'gtzan_genre'])\n",
    "\n",
    "dataroots = []\n",
    "dataroots.append([None, None])\n",
    "dataroots.append([None,\n",
    "                  PATH_PROCESSED,\n",
    "                  PATH_URBANSOUND,\n",
    "                  None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- model 0 weights are loaded. (NO ELM!!!) -----\n",
      "\n",
      "Start: mid_idx: 0, task_idx: 0\n",
      "ballroom_extended: Dataframe with size:4180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kchow/.conda/envs/TLMusic/lib/python2.7/site-packages/ipykernel/__main__.py:8: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'endswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-35f371e4007b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtask_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataroots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nStart: mid_idx: {}, task_idx: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpy_suffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done: mid_idx: {}, task_idx: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-732579a072fe>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(filename, batch_size, model, dataroot, npy_suffix)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFOLDER_CSV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}: Dataframe with size:{}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mexample_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filepath'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'An example path - does it exists? {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kchow/.conda/envs/TLMusic/lib/python2.7/posixpath.pyc\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m+=\u001b[0m  \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'endswith'"
     ]
    }
   ],
   "source": [
    "for mid_idx in range(5):\n",
    "    model = load_model_for_mid(mid_idx)\n",
    "    npy_suffix = '_layer_{}'.format(mid_idx)\n",
    "    for task_idx, (filename, dr) in enumerate(zip(tasks, dataroots)):\n",
    "        print('\\nStart: mid_idx: {}, task_idx: {}'.format(mid_idx, task_idx))\n",
    "        predict(filename, batch_size, model, dr, npy_suffix)\n",
    "        print('Done: mid_idx: {}, task_idx: {}'.format(mid_idx, task_idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Due to the Keras 2.0 API change (BatchNormalization) my model can't be loaded. You can use Keras 1.1 to reproduce it, or just use features under `data_feats` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO THE JOBS Set 1 - task 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtzan_speechmusic\n",
      "gtzan_speechmusic: Dataframe with size:128\n",
      "Index([u'Unnamed: 0', u'id', u'filepath', u'label'], dtype='object')\n",
      "MFCC is done! in 16.6159 sec\n",
      "ballroom_extended\n",
      "ballroom_extended: Dataframe with size:4180\n",
      "Index([u'Unnamed: 0', u'id', u'filepath', u'label'], dtype='object')\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/kchow/datasets/ballroom_extended_2016/Foxtrot/114427.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-1e165cf49d83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'gtzan_speechmusic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ballroom_extended'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gtzan_genre'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mget_mfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-7fd0df2f210d>\u001b[0m in \u001b[0;36mget_mfcc\u001b[0;34m(filename, dataroot)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_JOBS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path_to_mfccs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFOLDER_FEATS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpy_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kchow/.conda/envs/TLMusic/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    251\u001b[0m         '''\n\u001b[1;32m    252\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mRUN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kchow/.conda/envs/TLMusic/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/kchow/datasets/ballroom_extended_2016/Foxtrot/114427.mp3'"
     ]
    }
   ],
   "source": [
    "for filename in ['gtzan_speechmusic', 'ballroom_extended', 'gtzan_genre', ]:\n",
    "    print filename\n",
    "    get_mfcc(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tasks = ['emoMusic', 'jamendo_vd', 'urbansound']\n",
    "dataroots = [None, \n",
    "             PATH_PROCESSED,\n",
    "             os.path.join(PATH_URBANSOUND, 'audio')]\n",
    "for idx, (filename, dr) in enumerate(zip(tasks, dataroots)):\n",
    "    get_mfcc(filename, dataroot=dr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TLMusic]",
   "language": "python",
   "name": "conda-env-TLMusic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
